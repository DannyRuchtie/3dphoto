<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3D Photo Viewer</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.7.4/dist/tf.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <style>
        body { margin: 0; }
        canvas { display: block; }
        #upload-container {
            position: absolute;
            top: 20px;
            left: 20px;
            background: rgba(255, 255, 255, 0.8);
            padding: 20px;
            border-radius: 8px;
            z-index: 1000;
        }
        #status {
            margin-top: 10px;
            color: #333;
        }
        #tempCanvas {
            display: none;
        }
        #depthPreview {
            position: absolute;
            bottom: 20px;
            right: 20px;
            background: rgba(255, 255, 255, 0.8);
            padding: 10px;
            border-radius: 8px;
            max-width: 200px;
        }
    </style>
</head>
<body>
    <div id="upload-container">
        <input type="file" id="imageInput" accept="image/*">
        <button onclick="processImage()">Process & View in 3D</button>
        <div id="status"></div>
    </div>
    <canvas id="tempCanvas"></canvas>
    <div id="depthPreview">
        <h3>Depth Map Preview</h3>
        <canvas id="previewCanvas"></canvas>
    </div>

    <script>
        let scene, camera, renderer;
        let mesh;
        let model;

        const CORS_PROXY = 'https://cors-anywhere.herokuapp.com/';

        class Pydnet {
            async init() {
                const MODEL = "https://raw.githubusercontent.com/FilippoAleotti/demo_live/master/assets/js/pydnet.json";
                this.model = await tf.loadGraphModel(MODEL);
                this.modelHeight = 384;
                this.modelWidth = 640;
                return this;
            }

            async predict(img) {
                const aspectRatio = img.width / img.height;
                let outputWidth, outputHeight;
                
                if (aspectRatio > 1) {
                    outputWidth = 1920;
                    outputHeight = Math.round(1920 / aspectRatio);
                } else {
                    outputHeight = 1920;
                    outputWidth = Math.round(1920 * aspectRatio);
                }

                const [data, resizeInputData] = tf.tidy(() => {
                    const raw_input = tf.browser.fromPixels(img);
                    
                    const modelInput = tf.image.resizeBilinear(raw_input, [this.modelHeight, this.modelWidth]);
                    const preprocessedInput = modelInput.expandDims();
                    const normalizedInput = tf.div(preprocessedInput, 255.0);
                    
                    const result = this.model.predict(normalizedInput);
                    let processedResult = this.prepareOutput(result);
                    
                    const resizedResult = tf.image.resizeBilinear(
                        processedResult.expandDims(2),
                        [outputHeight, outputWidth],
                        true
                    );
                    
                    const finalInput = tf.image.resizeBilinear(raw_input, [outputHeight, outputWidth]);
                    const finalInputInt = tf.cast(finalInput, "int32");
                    
                    const data = resizedResult.squeeze().dataSync();
                    const resizeInputData = finalInputInt.dataSync();
                    return [data, resizeInputData, outputWidth, outputHeight];
                });
                await tf.nextFrame();
                return [data, resizeInputData, outputWidth, outputHeight];
            }

            prepareOutput(tensor) {
                return tf.tidy(() => {
                    tensor = tf.relu(tensor);
                    tensor = tf.squeeze(tensor);
                    tensor = tf.expandDims(tensor, 2);
                    const gaussianKernel = tf.tensor2d(
                        [
                            [1, 2, 1],
                            [2, 4, 2],
                            [1, 2, 1]
                        ]
                    ).div(16).expandDims(2).expandDims(3);
                    
                    tensor = tf.conv2d(
                        tensor.expandDims(0),
                        gaussianKernel,
                        1,
                        'same'
                    ).squeeze();

                    const min_value = tf.min(tensor);
                    const max_value = tf.max(tensor);
                    const normalized = tf.div(
                        tf.sub(tensor, min_value),
                        tf.sub(max_value, min_value)
                    );
                    return tf.mul(normalized, 255.0);
                });
            }
        }

        function init() {
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            renderer = new THREE.WebGLRenderer({ antialias: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            document.body.appendChild(renderer.domElement);

            camera.position.z = 5;

            const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
            scene.add(ambientLight);

            const directionalLight = new THREE.DirectionalLight(0xffffff, 0.5);
            directionalLight.position.set(5, 5, 5);
            scene.add(directionalLight);

            animate();
        }

        async function processImageElement(imageElement) {
            try {
                const [depthData, resizeInputData, width, height] = await model.predict(imageElement);
                
                const tempCanvas = document.getElementById('tempCanvas');
                const previewCanvas = document.getElementById('previewCanvas');
                tempCanvas.width = width;
                tempCanvas.height = height;
                previewCanvas.width = 200;
                previewCanvas.height = Math.round(200 * (height / width));

                const ctx = tempCanvas.getContext('2d');
                const imageData = ctx.createImageData(width, height);
                
                let i = 0;
                for (let y = 0; y < height; y++) {
                    for (let x = 0; x < width; x++) {
                        const index = y * width + x;
                        const depth = depthData[index];
                        imageData.data[i] = depth;
                        imageData.data[i + 1] = depth;
                        imageData.data[i + 2] = depth;
                        imageData.data[i + 3] = 255;
                        i += 4;
                    }
                }
                
                ctx.putImageData(imageData, 0, 0);

                const previewCtx = previewCanvas.getContext('2d');
                previewCtx.drawImage(tempCanvas, 0, 0, previewCanvas.width, previewCanvas.height);

                createDisplacementMesh(imageElement, tempCanvas, width / height);
                return true;
            } catch (error) {
                console.error('Error processing image:', error);
                throw error;
            }
        }

        async function processImage() {
            const fileInput = document.getElementById('imageInput');
            const statusDiv = document.getElementById('status');
            
            if (!fileInput.files.length) {
                statusDiv.textContent = 'Please select an image first';
                return;
            }

            statusDiv.textContent = 'Processing image...';

            const img = new Image();
            img.onload = async function() {
                try {
                    await processImageElement(img);
                    statusDiv.textContent = 'Processing complete!';
                } catch (error) {
                    statusDiv.textContent = 'Error processing image: ' + error.message;
                }
            };
            
            img.src = URL.createObjectURL(fileInput.files[0]);
        }

        function createDisplacementMesh(imageElement, depthCanvas, aspectRatio) {
            const texture = new THREE.Texture(imageElement);
            texture.needsUpdate = true;

            const depthTexture = new THREE.Texture(depthCanvas);
            depthTexture.minFilter = THREE.LinearFilter;
            depthTexture.magFilter = THREE.LinearFilter;
            depthTexture.needsUpdate = true;

            if (mesh) {
                scene.remove(mesh);
            }

            const width = 3;
            const height = width / aspectRatio;
            const geometry = new THREE.PlaneGeometry(
                width, 
                height, 
                Math.min(512, Math.round(512 * aspectRatio)),
                Math.min(512, Math.round(512 / aspectRatio))
            );
            const material = new THREE.MeshPhongMaterial({
                map: texture,
                displacementMap: depthTexture,
                displacementScale: 0.2,
                displacementBias: -0.15,
                side: THREE.DoubleSide,
                flatShading: false,
                roughness: 0.5,
                metalness: 0.1,
                shininess: 0
            });

            mesh = new THREE.Mesh(geometry, material);
            scene.add(mesh);

            camera.position.z = Math.max(4, 3 + 2 * aspectRatio);
        }

        function animate() {
            requestAnimationFrame(animate);
            if (mesh) {
                mesh.rotation.y += 0.005;
            }
            renderer.render(scene, camera);
        }

        // Initialize Three.js scene
        init();

        // Initialize depth estimation model
        async function setupModel() {
            const statusDiv = document.getElementById('status');
            try {
                statusDiv.textContent = 'Loading model...';
                model = await new Pydnet().init();
                statusDiv.textContent = 'Model loaded, loading default image...';
                await loadDefaultImage();
            } catch (error) {
                console.error('Error setting up model:', error);
                statusDiv.textContent = 'Error loading model: ' + error.message;
            }
        }
        setupModel();

        // Handle window resizing
        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });

        // Add mouse controls for rotation
        let isDragging = false;
        let previousMousePosition = { x: 0, y: 0 };

        document.addEventListener('mousedown', (e) => {
            isDragging = true;
        });

        document.addEventListener('mousemove', (e) => {
            if (isDragging && mesh) {
                const deltaMove = {
                    x: e.offsetX - previousMousePosition.x,
                    y: e.offsetY - previousMousePosition.y
                };

                mesh.rotation.y += deltaMove.x * 0.01;
                mesh.rotation.x += deltaMove.y * 0.01;
            }

            previousMousePosition = {
                x: e.offsetX,
                y: e.offsetY
            };
        });

        document.addEventListener('mouseup', () => {
            isDragging = false;
        });

        async function loadDefaultImage() {
            const statusDiv = document.getElementById('status');
            statusDiv.textContent = 'Loading default image...';

            const img = new Image();
            img.crossOrigin = "Anonymous";
            
            img.onerror = () => {
                statusDiv.textContent = 'Failed to load default image';
            };

            img.onload = async function() {
                try {
                    await processImageElement(img);
                    statusDiv.textContent = 'Default image loaded and processed!';
                } catch (error) {
                    console.error('Error processing default image:', error);
                    statusDiv.textContent = 'Error processing default image';
                }
            };
            
            // Set default image source
            img.src = 'temp2.jpg';
        }

        async function predict(model, image) {
            // Convert image to tensor and normalize
            const tensor = tf.browser.fromPixels(image)
                .resizeBilinear([384, 384]) // MiDaS model expects 384x384 input
                .expandDims(0)
                .toFloat()
                .div(255.0);

            // Run prediction
            try {
                const prediction = await model.predict(tensor);
                
                // Ensure proper axis handling (this is where the error was occurring)
                const depthMap = prediction.squeeze(); // Remove batch dimension
                
                // Normalize depth values to 0-1 range
                const normalizedDepth = depthMap.sub(depthMap.min())
                                                .div(depthMap.max().sub(depthMap.min()));
                
                // Convert to image data
                const depthArray = await normalizedDepth.data();
                const width = depthMap.shape[1];
                const height = depthMap.shape[0];
                
                // Create canvas for depth map
                const canvas = document.createElement('canvas');
                canvas.width = width;
                canvas.height = height;
                const ctx = canvas.getContext('2d');
                const imageData = ctx.createImageData(width, height);
                
                // Fill image data with depth values
                for (let i = 0; i < depthArray.length; i++) {
                    const value = Math.floor(depthArray[i] * 255);
                    imageData.data[i * 4] = value;     // R
                    imageData.data[i * 4 + 1] = value; // G
                    imageData.data[i * 4 + 2] = value; // B
                    imageData.data[i * 4 + 3] = 255;   // A
                }
                
                ctx.putImageData(imageData, 0, 0);
                
                // Clean up tensors
                tensor.dispose();
                prediction.dispose();
                depthMap.dispose();
                normalizedDepth.dispose();
                
                return canvas;
            } catch (error) {
                console.error('Error in depth estimation:', error);
                throw error;
            }
        }

        async function processImage(imageElement) {
            try {
                const model = await tf.loadGraphModel('path/to/your/model.json');
                const depthMap = await predict(model, imageElement);
                
                // Update the depth map preview
                const previewContainer = document.querySelector('.depth-map-preview');
                if (previewContainer) {
                    previewContainer.innerHTML = '';
                    previewContainer.appendChild(depthMap);
                }
                
                // Use the depth map for Three.js visualization
                updateThreeJsScene(imageElement, depthMap);
            } catch (error) {
                console.error('Processing failed:', error);
            }
        }

        function updateThreeJsScene(originalImage, depthMap) {
            // Create texture from depth map
            const depthTexture = new THREE.CanvasTexture(depthMap);
            
            // Create displacement material
            const material = new THREE.MeshStandardMaterial({
                map: new THREE.TextureLoader().load(originalImage.src),
                displacementMap: depthTexture,
                displacementScale: 50, // Adjust this value to control depth effect
                displacementBias: 0
            });

            // Update your mesh with the new material
            // ... rest of your Three.js code
        }
    </script>
</body>
</html> 